\section{Introduction}

Code that handles untrusted inputs, such as processing network
data or parsing a file, is error-prone and is often exploited by
attackers.  This is in part because attackers have precise control
over the inputs to that code, and can craft inputs that trigger
subtle corner cases in input processing.  For example, the libpng
library has had 24 remotely exploitable vulnerabilities from 2007 to
2013,\footnote{\url{http://www.cvedetails.com/vulnerability-list/vendor_id-7294/Libpng.html}}
and Adobe's PDF and Flash viewers have been notoriously
plagued by input processing vulnerabilities.  Even relatively
simple formats, such as those used by the zlib compression
library, have had input processing vulnerabilities in the
past.\footnote{\url{http://www.cvedetails.com/vulnerability-list/vendor_id-72/product_id-1820/GNU-Zlib.html}}

A promising approach to avoid such vulnerabilities is to specify
a precise grammar for the input data format, and to build a tool for
parsing inputs given a particular grammar, such as the traditional {\tt
lex} and {\tt yacc} generators.  Applications that use such a tool to
process input data will not need to write error-prone input processing
code, and as long as the tool is bug-free, the application will be safe
from input processing vulnerabilities.

Unfortunately, grammars are seldom used directly to recognise
machine-created input. For example, the security-critical and very
well-engineered MIT Kerberos distribution uses parser generators, but
only for handling configuration files. A notable exception is the Mongrel
web server\footnote{\url{http://mongrel2.org/}} which uses a grammar
for HTTP written in the Ragel~\cite{ragel-paper} regular expression
language. Mongrel was re-written from scratch multiple times to achieve
better scaleability and design, yet the grammar could be  re-used across
all iterations~\cite{patterson-citation}.

Parser generators for binary protocols were first introduced by the
Hammer\footnote{\url{http://github.com/upstandinghackers/hammer/}} parser.
While previous parser generators could also be used to write grammars
for binary protocols\footnote{Theoretically speaking, the alphabet
over which a grammar is an  abstract set, so most algorithms work
just as well on an alphabet of $\{0,1\}$}, doing so is impractically
inconvenient. Hammer allows the programmer to specify a grammar in
terms of bits and bytes instead of characters. Common concerns, such as
endianness and bit-packing are transparently hidden by the library. Hammer
implements grammars as language-integrated parser combinators, an approach
popularised by Parsec for Haskell~\cite{LeijenMeijer:parsec}. The
parser combinator style (to our knowledge, first  described
in~\cite{burge1975recursive}) is a natural way of concisely expressing
top-down grammars~\cite{Danielsson:2010:TPC:1863543.1863585}\footnote{For
more background on the history of expressing grammars, see Bryan Ford's
masters thesis~\cite{ford2002packrat}, which also describes the default
parsing algorithm used by Hammer} by composing them from one or multiple
sub-parsers.  Hammer then constructs a tree of function pointers which
can be invoked to parse a given input into an abstract syntax tree (AST).

Working with generic tree structures is tiresome, so the programmer can
bind a \textit{semantic action} to a sub-parser. Whenever the sub-parser
is successfully invoked, the parser executes the semantic action on the
output of the sub-parser and places the result as a leaf node in the
syntax tree. Other parser generators frequently skip the AST entirely,
requiring the programmer to specify a semantic action with every rule
in the grammar.

Semantic actions are one source of vulnerability within automatically
generated parsers, as they are typically implemented in C or another
general purpose programming language and perform dangerous operations
such as memory allocation and copying. If there is a bug in the semantic
actions, the attacker is likely able to craft an input that invokes the
semantic actions with controllable inputs, as the inputs have not been
fully verified yet.

\subsection{Motivation}

\paragraph{Motivation}

While it is possible to express short transformations on the input
entirely as semantic actions\footnote{This is in fact the design
rationale, to perform computation on the fly as the parser walks the
parse tree.}, more complicated programs usually construct an internal
representation, which contains all relevant information from the input
in a format native to the programming language used. For example, a C
programmer ideally wants to deal with structs and NULL-terminated arrays,
whereas a C++ programmer might expect STL containers, a Java programmer
interfaces, a Haskell programmer records and a LISP programmer property
lists.  The structure of this internal representation usually resembles
the structure of the grammar.

Therefore, a typical programmer has to describe the structure of his input
twice or even thrice to use a parser generator. Once, to write a grammar,
another time to write the semantic actions constructing his favourite
intermediate representation. In most languages the programmer also
has to write explicit type definitions, which describe the intermediate
object model again. Most programmers will baulk at this multiplication of
efforts and either hand-write a top-down parser which still eliminates
writing the semantic actions at the slight cost of verbosity or resort
to passing user input through their control flow, hopefully remembering
to verify each part before it is accessed.

A similar problem occurs when the programmer wants to generate output.
Even though not all programs may use the same format for output as they
do on input, different programs might use the same format for input and
output and re-using the same grammar is a good way to save engineering
effort and reduce parser differentials.  Some parser generators, e.g.
Boost.Spirit,\footnote{\url{http://www.boost.org/doc/libs/1_55_0/libs/spirit/doc/html/index.html}}
allow the same grammar to be re-used for generating output from the
intermediate representation.  However, those generators require a new set
of semantic actions to be written, even though the relationship between
grammar and intermediate model was already expressed in the actions for
the parser.

