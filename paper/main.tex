\documentclass[10pt]{article}
\usepackage{graphicx}
\usepackage{url}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{underscore}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage{fullpage}


\begin{document}
\author{Julian Bangert, Nickolai Zeldovich, Frans Kaashoek} 
\date{}
\title{Nail: A practical interface generator for binary formats \\ \small-How to avoid hitting
  your security assumptions when dealing with untrusted input-}
\maketitle

 \abstract{We present \textit{Nail},
  an interface generator that allows programmers to safely parse and generate protocols defined by a
  Parser-Expression based grammar. Nail uses a richer set of parser combinators that induce an
  internal representation, obviating the need to write semantic actions. Nail also provides
  solutions parsing common patterns such as length and offset fields within binary formats that are
  hard to process with existing parser generators.}
\section{Background}


% For a long time, it has been possible to write a concise and precise specification of what a data
% format looks like, feed it to a tool and let it generate a parser and potentially a generator for
% that format. However, instead of using these tools, programmers have continued to laboriously
% hand-write bug-prone input/output code. One of the reasons they have done so is that existing tools
% were geared towards parsing text-based programming languages, not for dealing with binary protocols,
% although the underlying algorithms remain the same.  


\subsection{Problems handling untrusted input}
Code handling untrusted user inputs is most prone to contain security vulnerabilities. While memory
corruption errors or fatal logic flaws can occur anywhere in a program, bugs in the input handling
code are most likely to be exploitable, because an attacker has total control over the inputs to
that code. 

Common wisdom thus says to take special care when preparing code that deals with untrusted input.
However, with currently prevalent software design methods, it is hard to isolate input-handling code
from the rest of the program, as user input is typically passed through the program and processed in
bits and pieces as a 'shotgun parser'\cite{shotgun-parser}.  

A look at the CVE database or Hacker journal such as \textit{Phrack} shows that such design patterns
and the security problems they cause are rampant. Input processing libraries such as libpng
\footnote{\url{http://www.cvedetails.com/vulnerability-list/vendor_id-7294/Libpng.html} shows 24
remote exploits in the between 2007 and 2013.} or Adobe's PDF and Flash viewers are notoriously
plagued with input bugs. Even simpler formats such as the \textit{zlib} compression library have
historically contained multiple security
flaws\footnote{\url{http://www.cvedetails.com/vulnerability-list/vendor_id-72/product_id-1820/GNU-Zlib.html}}.

Besides memory corruption vulnerabilities - against which various mitigations such as static
analysis, dynamic instrumentation and various memory protection mechanisms have been developed -
different implementations of the same format can also differ in their understanding of some edge
cases. The security of many systems relies on different components interpreting the same data
similarly.

Such parser differential vulnerabilities were found in various cryptographic systems, including  iOS
\footnote{The XNU kernel and the user code-signing verifier interpret executable metadata
  differently, so the code signature sees different bytes at a virtual address than the executable
  that runs.}\cite{evaders6} and Android\footnote{Android applications are distributed as .zip
  files. Signatures are verified with a Java program, but the program is extracted with a C program.
The java program interprets all fields as signed, whereas the C program treats them as unsigned,
allowing one to replace files in a signed archive.}
\cite{saurik-masterkey} code signing and even the
X.509 protocol underlying SSL \cite{DBLP:conf/fc/KaminskyPS10}. Such vulnerabilities occur even if the language,
runtime environment or static analysis guarantee absolute memory safety.

Finally, many protocol implementations are so complicated that even without bugs, they inadvertently
provide a full Turing-complete execution environment. Examples include X86 page tables
\cite{bangert2013page}, ELF symbols and relocations\cite{shapiro2013weird}.  
The more powerful an input
protocol is, the more control an attacker gains over a systems state - and power to manipulate a
systems state is also a degree of undeserved trust. In the offensive research community, this has
been generalised into treating a program as a \textit{weird machine}\cite{bratus2011exploit} that
operates on an input, analogous to a virtual machine operating on bytecode.

Proper input recognition has been shown to be an excellent way of eliminating malicious inputs. In
one case, a hand-written PDF parser could eliminate $98\%$ of known malicious PDFs\cite{Bogk-PDF}.


\subsection{Parser generators}
%%TODO
Luckily, we can avoid all of these problems at once if we have a single, executable specification of
what exactly a programs input is supposed to look like. In fact, definitive grammars have long
been written for all sorts of protocols and are the standard way of describing text-based protocols.
Parser generators can automatically create parsers for such languages, and with common classes of
grammars such as regular expressions or deterministic context free languages, that parser can be
expressed in a computationally less powerful form, e.g. a finite automaton or a push down automaton,
limiting the weird machine problem and enabling very efficient implementation. \cite{Knuth1965607}


Specifications of binary protocols, such as RFCs, also contain grammars, although they are
frequently translated into prose and diagrams as opposed to the traditional Backus-Naur-Form.  


Unfortunately, grammars are seldom used directly to recognise machine-created input. For example,
the security-critical and very well-engineered MIT Kerberos distribution uses parser
generators, but only for handling configuration files. A notable exception is the Mongrel
web server \footnote{\url{http://mongrel2.org/}} which uses a grammar for HTTP written in the
Ragel \cite{ragel-paper} regular expression language. Mongrel was re-written from scratch multiple
times to achieve better scaleability and design, yet the grammar could be  re-used across all iterations\cite{patterson-citation}.

 Parser generators for binary protocols were first introduced by the Hammer\footnote{\url{http://github.com/upstandinghackers/hammer/}} parser.
 While previous parser generators could also be used to write grammars for binary
 protocols\footnote{Theoretically speaking, the alphabet over which a grammar is an  abstract set,
   so most algorithms work just as well on an alphabet of $\{0,1\}$}, doing so is impractically
 inconvenient. Hammer allows the programmer to specify a grammar in terms of bits and bytes instead
 of characters. Common concerns, such as endianness and bit-packing are transparently hidden by the
 library. Hammer implements grammars as language-integrated parser combinators, an approach
 popularised by Parsec for Haskell\cite{LeijenMeijer:parsec} and. The parser combinator style (to our
 knowledge, first  described in \cite{burge1975recursive}) is a natural way of concisely expressing
 top-down grammars\cite{Danielsson:2010:TPC:1863543.1863585} \footnote{For more background on the history of expressing grammars, see Bryan
   Ford's masters thesis\cite{ford2002packrat}, which also describes the default parsing algorithm used by Hammer} by composing them from one or multiple sub-parsers. 
  Hammer then constructs a tree of function pointers which
 can be invoked to parse a given input into an abstract syntax tree (AST).
 
Working with generic tree structures is tiresome, so the programmer can bind a \textit{semantic action} to a
sub-parser. Whenever the sub-parser is successfully invoked, the parser executes the semantic action
on the output of the sub-parser and places the result as a leaf node in the syntax tree. Other
parser generators frequently skip the AST entirely, requiring the programmer to specify a semantic
action with every rule in the grammar. 

Semantic actions are one source of vulnerability within automatically generated parsers, as they are
typically implemented in C or another general purpose programming language and perform dangerous
operations such as memory allocation and copying. If there is a bug in the semantic actions, the
attacker is likely able to craft an input that invokes the semantic actions with controllable
inputs, as the inputs have not been fully verified yet.

\subsection{Motivation}
\paragraph{Motivation}
While it is possible to express short transformations on the input entirely as semantic actions
\footnote{This is in fact the design rationale, to perform computation on the fly as the parser
  walks the parse tree.}, more complicated programs usually construct an internal representation,
which contains all relevant information from the input in a format native to the programming
language used. For example, a C programmer ideally wants to deal with structs and NULL-terminated
arrays, whereas a C++ programmer might expect STL containers, a Java programmer interfaces, a
Haskell programmer records and a LISP programmer property lists. 
 The structure of this internal representation usually resembles the structure of the grammar. 

Therefore, a typical programmer has to describe the structure of his input twice or even thrice to
use a parser generator. Once, to write a grammar, another time to write the semantic actions
constructing his favourite intermediate representation. In most languages the programmer also has to
write explicit type definitions, which describe the intermediate object model again. Most
programmers will baulk at this multiplication of efforts and either hand-write a top-down parser
which still eliminates writing the semantic actions at the slight cost of verbosity or resort to
passing user input through their control flow, hopefully remembering to verify each part before
it is accessed. 

A similar problem occurs when the programmer wants to generate output. 
Even though not all programs may use the same format for output as they do on input, different
programs might use the same format for input and output and re-using the same grammar is a good way
to save engineering effort and reduce parser differentials.
Some parser generators, e.g.
Boost.Spirit \footnote{\url{http://www.boost.org/doc/libs/1_55_0/libs/spirit/doc/html/index.html}},
allow the same grammar to be re-used for generating output from the intermediate representation.
However, those generators require a new set of semantic actions to be written, even though the
relationship between grammar and intermediate model was already expressed in the actions for the
parser.

\section{Design}

\paragraph{Overview}
To alleviate these problems, Nail provides a richer set of combinators that induce the structure of
an internal model, while also describing the grammar of the external protocol. Nail takes the
combinators and produces type declarations for an internal model, the \textit{parser}, a function to parse a sequence of
bytes into an instance of the model and the \textit{generator}, a function to create a sequence of
bytes from an instance of the model.

A central design decision of Nail is that there is a  bijection between the model exposed to the programmer and the bytes
input and output up to syntactic equivalence. More precisely, the parser is the generators inverse,
so parsing the generators output will yield the generators input, but generating the parsers output
does not necessarily yield the parsers input. To understand why this makes sense, consider a grammar
for a text language that tolerates white space or a binary protocol that tolerates arbitrarily long
padding\footnote{Say, the physical layer of most communication protocols is a possibly infinite
  sequence of symbols that are syntactically nil followed by a pre-determined synchronisation
  sequence and the actual contents of the transmission.}. However, if some features of Nail are
avoided, there is a proper isomorphism between model and protocol.

In the following, we present the combinators in Nail grouped by the combinators, if possible grouped
by the combinator of conventional Parser Expression Grammars they replace.
\paragraph{Fundamental parsers}
The elementary parsers of Nail are the same as those of Hammer, signed and unsigned integers with
arbitrary lengths up to 64 bits. Note that is possible to define parsers for sub-byte lengths, e.g.
to parse the 4-bit data offset within the TCP header. Integer parsers return their value in the
smallest appropriately sized machine integer type, e.g. a 24 bit integer is stored in a 32-bit wide variable.\\
Examples: \texttt{uint4}, \texttt{int32}

Integer parsers can be constrained to fall either within an (inclusive) range of values or be an
element of a set of allowed values. \\Examples: \texttt{uint8 | 1..3},\texttt{uint16| ..512},
\texttt{int32| [1,255,512]}

\paragraph{Constant parser}
Nail also has constant parsers, which do not return a value. The simplest constant parser is an
integer with fixed value, e.g. \texttt{uint8=0}. Constant parsers succeed if the inner integer
parser returns the given value and fail otherwise. 


\paragraph{Sequence: Structure}
Nails fundamental concept is the structure combinator. It contains a list of named parsers and
unnamed constant parsers. 
When parsing, it parses each parser in sequence and returns a structure containing the result of
each parser.

\begin{tabular}{ll}
\textbf{Nail} & \textbf{Data Model}\\
\begin{minipage}{2in}
\begin{verbatim}
header = {
 id uint16
 qr uint1
 opcode uint4
 aa uint1 
 tc uint1
 rd uint1
 ra uint1
 uint3 = 0
 rcode uint4
}
\end{verbatim} 
\end{minipage}
 & 
\begin{minipage}{2in}
\begin{verbatim}
struct header{
    uint16_t id;
    uint8_t qr;
    uint8_t opcode;
    uint8_t aa;
    uint8_t tc;
    uint8_t rd;
    uint8_t ra;
    uint8_t rcode;
};
\end{verbatim} 
\end{minipage} 
\\
\end{tabular}
\paragraph{Repetition: Many,SepBy}
The many combinator takes a parser and applies it repeatedly until it fails, returning an array of
the inner parsers results. SepBy additionally takes a constant parser, which it applies in between
parsing two values,but not before parsing the first value or after parsing the last.\\
Examples \texttt{many uint8}, \texttt{sepBy uint8=',' (many uint8| '0'..'9')} (which recognises
comma-separated lists of numbers).

The many combinator also works on constant parsers, although as described above it can make the
generator not bijective. \footnote{By default, the generator will emit exactly one iteration of the
  constant parser in its output.} Example: \texttt{many uint8= "test"}


\paragraph{Semantic choice: choose}
We extend PEG's ordered choice combinator, which picks the first choice that succeeds, with a tag
for each choice. The result is saved in a tagged union. 

\begin{verbatim}
choose {
   A = uint8 | 1.. 8
   B = uint16 | ..256
}
\end{verbatim}
\paragraph{Wrap}

The wrap combinator parses one or more constant parser, then an inner parser whose value it returns
and then again parses one or more constant parsers.\\ Example: 
\verb+<uint8='"'; many8 uint8|'a'..'z'; uint8='"'  >+

\subsection{Offset fields}
Another problem for parser generators is that binary protocols often contain length and offset
fields. While conventional parsing algorithms can deal with bounded offset fields - a finite
automaton can count a bounded integer, and we can feed the (finite) input multiple times to the
finite automaton. However, this implementation is both time-inefficient - why feed many bytes into
the automaton that will just be skipped - and very cumbersome to express with current parser
generators. Therefore, if languages with offset fields are parsed with parser generators, the only
currently feasible way is to add 'ad-hoc' hacks such as changing the input pointer of the generated
parser on the fly from semantic actions. 

Nail will properly support both offset and length fields and much of the following discussion
applies to both , although the current prototype only implements lengths, which we will focus on. 

\paragraph{Dependency fields}
We call length or offset fields \textit{dependency fields}, because during parsing, another parser
depends on them, and while generating output, their value depends on some other structure in the
data model.
Dependency fields appear in a structure combinator as would any other field, but their name begins
with an '@' sign and they have to return an integer value. Dependency fields are not directly
represented in the internal model. 

\paragraph{Length fields: n_of}
The length combinator takes a dependency field and a parser, evaluating the parser as often as the
value of the dependency field, returning an array of the values. When generating output, it emits
the array and writes its length to the dependency field. 

\subsection{Example Grammars}
To further familiarise the reader with Nail, we provide two example grammars. 
\paragraph{UTF-16}
This grammar recognises valid UTF-16 strings and exposes an array of code points. 

\begin{tabular}{ll}
\textbf{Nail} & \textbf{Data Model}\\
\begin{minipage}{3in}
\begin{verbatim}
utfstring = many choose {
         SUPP= {
               lead uint16 | 55296..56319
                          // 0xD800..0xDBFF
               trail uint16 | 56320..57343
                          // 0xDC00..0xDFFF
               }
         BASIC = uint16 | !55296..57343
       }
\end{verbatim}
\end{minipage}
 & 
\begin{minipage}{2in}
\begin{verbatim}
struct utfstring {
 struct {
   enum  {SUPP,BASIC} N_type;
   union {
    struct {
     uint16_t lead;
     uint16_t trail;
    } SUPP;
    uint16_t BASIC;
   };
 }*elem;
 size_t count;
};
\end{verbatim} 
\end{minipage} 
\\
\end{tabular}

\paragraph{DNS packet}
This grammar recognises DNS packets without label compression, as per RFC1035 
\begin{verbatim}
labels = <many {@length  uint8 | 1..255 
                label n_of @length uint8 }
             uint8 = 0>
question= {   labels labels
              qtype uint16 | 1..16 
              qclass uint16 | [1,255]
               }
answer  = {
             labels labels
             rtype uint16 | 1..16
             class uint16 | [1]
             ttl uint32
             @rlength uint16 
             rdata n_of @rlength uint8 
             }
dnspacket = {id uint16
              qr uint1
              opcode uint4
              aa uint1 
              tc uint1
              rd uint1
              ra uint1
              uint3 = 0
              rcode uint4
              @questioncount uint16
              @answercount uint16
              authoritycount uint16   // Ignored
              additionalcount uint16  //Ignored       
              questions n_of @questioncount question         
              responses n_of @answercount answer
            }
\end{verbatim}


\section{Implementation}
The current prototype of the Nail parser generator supports the C programming language and top down parsers. Options for C++ STL data models and emitting Packrat parser
\cite{packrat-parsing:icfp02} are under heavy development. In this section, we will discuss some particular
features of our parser implementation.

\paragraph{Parsing}
A generated Nail parser makes two passes through the input , the first to validate and recognise the
input, the second to bind this data to the internal model. Currently the parser is a straightforward
top down parser, although facilities have been made to add Packrat parsing to achieve linear parsing times.
\paragraph{Memory allocation} 
Many security vulnerabilities can occur when heap allocations are done improperly. Therefore, just
like Hammer, Nail avoids using the heap as much as possible, using a custom arena allocator and
allocating only fixed size blocks from the system malloc. However, Nail extends upon Hammers
approach and uses two arenas for each parsed input. One arena is used for intermediate results and is
freed(and zeroed) after parsing completes, whereas the other arena is used only for allocating the
result and has to be freed by the programmer. 

\paragraph{Intermediate representation}
Most parser generators, such as Bison do not have to dynamically allocate temporary
data, as they evaluate a semantic action on every rule. However, as our goal is to perform as little
computation as possible without having validated the input, and we do not want to mix temporary
objects with the results of our parse, we need some intermediate structure to cache parse results.
This structure is also used as a value in the Packrat hash table. 

Hammer solves this problem by storing a full abstract syntax tree. However, this abstract syntax
tree is at least an order of magnitude larger than the input, because it stores a large tree node
structure for each input byte and for each rule reduced. This allows Hammer semantic actions to get
all necessary information without ever seeing the raw input stream. However, because we also
automatically generate our second pass, which corresponds to Hammers semantic actions, we can trust
it as much as we trust the parser and thus expose it to the raw input stream. 

Under this premise, the actions need very limited information from the recogniser to correctly
handle the input stream. In particular, the parsers control flow only branches at the choice and
repeat combinators. For all other combinators, the action just has to assign a fixed sequence of
fundamental parsers to a fixed sequence of internal model fields. 
Thus we can represent the parsers success as a sequence of selected choices and counted repeats and
use this to reconstruct the syntax of the input. %TODO: This sentence is HORRIBLE. Re-work 
\paragraph{Dependency Fields}
During parsing, dependency fields occur before the context in which they are used. The parser stores
their value and retrieves it afterwards when encountering the combinator that uses them. When
generating output, the dependency field is first filled with a filler value, then later when the
first combinator that determines this fields value is encountered, the field is overwritten. Any
further combinators using this dependency will then validate that the dependency field is correct. 
\paragraph{Bootstrapping}
To demonstrate the feasibility of the nail parser generator, our parser generator uses a Nail parser
to recognise Nail grammars. A superset of the grammar language described in this paper is
implemented in 100 lines of Nail, which feed into about a thousand lines of C++ that implement the
actual parser generator. Bootstrapping is supported via an LALR implementation.
\section{Evaluation}
In order to test the Nail framework, we cloned the test DNS server from the Hammer distribution to
Nail. Hammer ships with a toy DNS server written in 683 lines of code, excluding the hammer
framework itself that responds to any valid DNS query with a CNAME record to the domain
``spargelze.it''.  Most of this code is taken up with custom validators, semantic actions and data
structure definitions. 

Our DNS server measures 148 lines of C and 48 lines of Nail grammar, and supports a custom zone file format
with A,NS,MX and CNAME records. The same grammar is used together with 98 lines of C to implement a
functional toy clone of the host command line tool. However, because our grammar does not yet
support DNS label compression, the latter tool will occasionally reject valid real world DNS
responses. Both clients have functional anti-spoofing measures.

It is hard to compare our efforts to a real world DNS server, as we have less functionality, in
particular for DNS compression and additional hint records than real world DNS servers. 
However, the closest in functionality and intent is Dan Bernstein's djbdns\footnote{\url{http://cr.yp.to/djbdns.html}}, which aims
to be a minimalist, highly secure DNS server. The latest release of DJBDNS, however, including
various support tools is about ten thousand lines of C as measured by SLOCCOUNT. We are confident
that it is possible to a feature-par version with Nail that is an order of magnitude smaller and
intend to do so.


\section{Future Work}

The Nail parser generator is work in progress and feedback of all sorts is heavily
encouraged. Source code is available upon request and will be released publicly pending clean-up and
maturity. Short-term future work will include improving the scoping of dependency fields and adding
support for offset fields.

A major problem with the current design of Nail is that the design of the grammar dictates the
interna structure of the software. This makes changing grammars or adding Nail to existing software
awkward. One possible solution to this problem would be to implement a concept similar to Relational
Lenses \cite{bohannon2006relational}, which would allow  the data model to be 'seen' by
the rest of the program through an isomorphism. Such an isomorphism would still be much more concise
than two sets of semantic actions, while allowing changes in syntax, alternative representations
and adaption to legacy systems.

Finally, we would like to demonstrate the capabilities of Nail by implementing various binary
formats 'notorious' for their insecurity in Nail. Nail was designed with the idioms of formats such
as PDF and PNG in mind. Ultimately, we want to provide examples of successful Nail parsers all
throughout a network stack - from a user-space TCP stack to a PNG de-compressor.

\subsection{Previous work}
Generating parsers and generators from an executable specification is the core concept of Interface
Generators, e.g. in CORBA or more recently\cite{varda2008}. However, while interface
generators work very well for existing grammars, they do not allow full control over the format of
the output, so cannot be used to implement legacy protocols.
Very related work has been done at Bell Labs with the PacketTypes system\cite{mccann2000packet},
however PacketTypes works only as a parser and does not support the expressive power of PEGs, but rather
implements a C like structure model enhanced with data-dependent length fields and constraints.
\begin{comment}

Memory corruption exploits (frequently) rely on placing controlled values at known (or controlled)
memory locations. Exploit countermeasures  like Address-Space Layout Randomisation\cite{pax-aslr},
 heap cookies \cite{heapcookies} or data execution prevention try to make this harder for
 an attacker. Attackers have developed techniques such as heap spraying \cite{heapspray} and heap
 feng shui\cite{fengshui} to help bypass those mitigations. 


Nail parsers use two arena allocators\cite{arena}, one for the temporary syntax tree and one for the
result. If Nail were to use the normal system allocator, the attacker could cause two packets to be
parsed at the same time (or, given a sufficiently complicated input, two structure within the same
grammar to be parsed sequentially) such that the (invalid) intermediate results from one parse,  
 If there is a buffer overflow past the
end of one input, it is much harder for the attacker craft a sequence of packets to trick the allocator into
placing a known value next to that input.

\end{comment}


\bibliography{main,locasto,login,phrack,short,langsec}
\bibliographystyle{plain}

\end{document} 