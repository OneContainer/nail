\section{Related work}
\label{s:relwk}

\paragraph{Language safety.}

Input processing vulnerabilities fall into two broad classes.  The first
class is memory safety bugs, such as buffer overflows, which allow an
adversary to corrupt the application's memory using specially crafted
inputs.  These mistakes arise in lower-level languages that do not
provide memory safety guarantees (such as C), and can be partially
mitigated by a wide range of techniques, such as static analysis,
dynamic instrumentation, and address space layout randomization, that
make it more difficult for an adversary to exploit these bugs.

The second class is logic errors, where application code misinterprets
input data.  This can lead to serious security consequences when two
systems disagree on the meaning of a network packet or a signed message,
as in iOS\footnote{The XNU kernel and the user code-signing verifier
interpret executable metadata differently, so the code signature
sees different bytes at a virtual address than the executable that
runs.}~\cite{evaders6} and Android\footnote{Android applications
are distributed as .zip files. Signatures are verified with a Java
program, but the program is extracted with a C program.  The Java
program interprets all fields as signed, whereas the C program
treats them as unsigned, allowing one to replace files in a signed
archive, thereby undermining Android's security model.}~\cite{saurik-masterkey} code signing and even the X.509 protocol
underlying SSL~\cite{DBLP:conf/fc/KaminskyPS10}.  These mistakes are
highly application-specific, and are difficult to mitigate using existing
techniques, and these mistakes can occur even in high-level languages
that guarantee memory safety.

A subclass of logic errors are so-called \textit{weird machines}, where implementation side effects
or under-specified parser behaviour leads to a protocol inadvertently becoming a Turing complete
execution environment. Frequently, this execution environment can either then directly manipulate
data in unwanted ways or be used to make exploiting another bug feasible\footnote{For example, by
  compiling a return-oriented-programming exploit from code fragments discovered on the fly}.
 Examples include X86 page tables~\cite{bangert2013page},
ELF symbols and relocations~\cite{shapiro2013weird}. In the offensive research community,
this has been generalised into treating a program as a \textit{weird
machine}~\cite{bratus2011exploit} that operates on an input, analogous
to a virtual machine operating on bytecode. 

% With currently prevalent software design methods, it is hard to isolate
% input-handling code from the rest of the program, as user input is
% typically passed through the program and processed in bits and pieces as a
% ``shotgun parser''~\cite{shotgun-parser}. Thus, partially invalid input might be partly 
% processed by the program until the invalid sections are encountered.

\paragraph{Parsing frameworks.}
Proper input recognition has  been shown to be an excellent way of
eliminating malicious inputs. In one case, a  PDF parser implemented in
Coq could eliminate over $95\%$ of known malicious PDFs~\cite{Bogk-PDF}.
However, manually writing parser code does not scale to the number of
file formats  and protocols in existence and might result in parser code
tied to one specific application.

Generating parsers and generators from an executable specification
is the core concept of Interface Generators, e.g. in CORBA or more
recently~\cite{varda2008}. However, while interface generators work
very well for existing grammars, they do not allow full control over the
format of the output, so cannot be used to implement legacy protocols.
Very related work has been done at Bell Labs with the PacketTypes
system~\cite{mccann2000packet}, however PacketTypes works only as a
parser, not as an output generator and does not support the expressive
power of PEGs, but rather implements a C like structure model enhanced
with data-dependent length fields and constraints.

Parser generators for binary protocols were first introduced by the
Hammer~\cite{hammer-parser} parser.
While previous parser generators could also be used to write grammars
for binary protocols\footnote{Theoretically speaking, the alphabet
over which a grammar is an  abstract set, so most algorithms work
just as well on an alphabet of $\{0,1\}$}, doing so is impractically
inconvenient. Hammer allows the programmer to specify a grammar in
terms of bits and bytes instead of characters. Common concerns, such as
endianness and bit-packing are transparently hidden by the library. Hammer
implements grammars as language-integrated parser combinators, an approach
popularised by Parsec for Haskell~\cite{LeijenMeijer:parsec}. The
parser combinator style (to our knowledge, first  described
in~\cite{burge1975recursive}) is a natural way of concisely expressing
top-down grammars~\cite{Danielsson:2010:TPC:1863543.1863585}\footnote{For
more background on the history of expressing grammars, see Bryan Ford's
masters thesis~\cite{ford2002packrat}, which also describes the default
parsing algorithm used by Hammer} by composing them from one or multiple
sub-parsers.  Hammer then constructs a tree of function pointers which
can be invoked to parse a given input into an abstract syntax tree (AST).



\paragraph{Application use of parsers.}
Generated parsers have long been used to parse human input, such as programming languages and
configuration files. Frequently, such languages are often specified with a formal grammar in an
executable form.

Unfortunately,  parser frameworks are seldom used  to recognise
machine-created input. For example, the security-critical and very
well-engineered MIT Kerberos distribution uses parser generators, but
only for handling configuration files. A notable exception is the Mongrel
web server\footnote{\url{http://mongrel2.org/}} which uses a grammar
for HTTP written in the Ragel~\cite{ragel-paper} regular expression
language. Mongrel was re-written from scratch multiple times to achieve
better scaleability and design, yet the grammar could be  re-used across
all iterations~\cite{patterson-citation}.


--- XXX integrate the following paragraphs somewhere into the logical flow ---




%%This is supposed to go into design
% While it is possible to express short transformations on the input
% entirely as semantic actions\footnote{This is in fact the design
% rationale, to perform computation on the fly as the parser walks the
% parse tree.}, more complicated programs usually construct an internal
% representation, which contains all relevant information from the input
% in a format native to the programming language used. For example, a C
% programmer ideally wants to deal with structs and NULL-terminated arrays,
% whereas a C++ programmer might expect STL containers, a Java programmer
% interfaces, a Haskell programmer records and a LISP programmer property
% lists.  The structure of this internal representation usually resembles
% the structure of the grammar.

