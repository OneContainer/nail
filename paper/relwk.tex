\section{Related work}
\label{s:relwk}

\paragraph{Parsing frameworks.}

Generating parsers and generators from an executable specification
is the core concept of Interface Generators, e.g. in CORBA or more
recently~\cite{varda2008}. However, while interface generators work
very well for existing grammars, they do not allow full control over the
format of the output, so cannot be used to implement legacy protocols.
Very related work has been done at Bell Labs with the PacketTypes
system~\cite{mccann2000packet}, however PacketTypes works only as a
parser, not as an output generator and does not support the expressive
power of PEGs, but rather implements a C like structure model enhanced
with data-dependent length fields and constraints.

Parser generators for binary protocols were first introduced by the
Hammer\cite{hammer-parser} parser.
While previous parser generators could also be used to write grammars
for binary protocols\footnote{Theoretically speaking, the alphabet
over which a grammar is an  abstract set, so most algorithms work
just as well on an alphabet of $\{0,1\}$}, doing so is impractically
inconvenient. Hammer allows the programmer to specify a grammar in
terms of bits and bytes instead of characters. Common concerns, such as
endianness and bit-packing are transparently hidden by the library. Hammer
implements grammars as language-integrated parser combinators, an approach
popularised by Parsec for Haskell~\cite{LeijenMeijer:parsec}. The
parser combinator style (to our knowledge, first  described
in~\cite{burge1975recursive}) is a natural way of concisely expressing
top-down grammars~\cite{Danielsson:2010:TPC:1863543.1863585}\footnote{For
more background on the history of expressing grammars, see Bryan Ford's
masters thesis~\cite{ford2002packrat}, which also describes the default
parsing algorithm used by Hammer} by composing them from one or multiple
sub-parsers.  Hammer then constructs a tree of function pointers which
can be invoked to parse a given input into an abstract syntax tree (AST).


\paragraph{Language safety.}

Input processing vulnerabilities fall into two broad classes.  The first
class is memory safety bugs, such as buffer overflows, which allow an
adversary to corrupt the application's memory using specially crafted
inputs.  These mistakes arise in lower-level languages that do not
provide memory safety guarantees (such as C), and can be partially
mitigated by a wide range of techniques, such as static analysis,
dynamic instrumentation, and address space layout randomization, that
make it more difficult for an adversary to exploit these bugs.

The second class is logic errors, where application code misinterprets
input data.  This can lead to serious security consequences when two
systems disagree on the meaning of a network packet or a signed message,
as in iOS\footnote{The XNU kernel and the user code-signing verifier
interpret executable metadata differently, so the code signature
sees different bytes at a virtual address than the executable that
runs.}~\cite{evaders6} and Android\footnote{Android applications
are distributed as .zip files. Signatures are verified with a Java
program, but the program is extracted with a C program.  The java
program interprets all fields as signed, whereas the C program
treats them as unsigned, allowing one to replace files in a signed
archive.}~\cite{saurik-masterkey} code signing and even the X.509 protocol
underlying SSL~\cite{DBLP:conf/fc/KaminskyPS10}.  These mistakes are
highly application-specific, and are difficult to mitigate using existing
techniques, and these mistakes can occur even in high-level languages
that guarantee memory safety.

\paragraph{Application use of parsers.}

Unfortunately, grammars are seldom used directly to recognise
machine-created input. For example, the security-critical and very
well-engineered MIT Kerberos distribution uses parser generators, but
only for handling configuration files. A notable exception is the Mongrel
web server\footnote{\url{http://mongrel2.org/}} which uses a grammar
for HTTP written in the Ragel~\cite{ragel-paper} regular expression
language. Mongrel was re-written from scratch multiple times to achieve
better scaleability and design, yet the grammar could be  re-used across
all iterations~\cite{patterson-citation}.



--- XXX integrate the following paragraphs somewhere into the logical flow ---

With currently prevalent software design methods, it is hard to isolate
input-handling code from the rest of the program, as user input is
typically passed through the program and processed in bits and pieces as a
``shotgun parser''~\cite{shotgun-parser}.

Many protocol implementations are so complicated that even
without bugs, they inadvertently provide a full Turing-complete execution
environment. Examples include X86 page tables~\cite{bangert2013page},
ELF symbols and relocations~\cite{shapiro2013weird}. Even though
these protocols were never intended to be that expressive -
and consequentially hard to parse, implementation details of their
recognisers - which de facto became a part of the specification and were
relied upon by legitimate inputs - expose unwanted computational power
and have unintended side-effects.  In the offensive research community,
this has been generalised into treating a program as a \textit{weird
machine}~\cite{bratus2011exploit} that operates on an input, analogous
to a virtual machine operating on bytecode.

Parser generators can automatically create parsers for such languages,
and with common classes of grammars such as regular expressions or
deterministic context free languages, that parser can be expressed in a
computationally less powerful form, e.g. a finite automaton or a push
down automaton, limiting the weird machine problem and enabling very
efficient implementation~\cite{Knuth1965607}.

Proper input recognition has been shown to be an excellent way of
eliminating malicious inputs. In one case, a  PDF parser implemented in
Coq could eliminate over $95\%$ of known malicious PDFs~\cite{Bogk-PDF}.
However, manually writing parser code does not scale to the number of
file formats  and protocols in existence and might result in parser code
tied to one specific application.

In fact, definitive grammars have long been written for all sorts of
protocols and are the standard way of describing text-based protocols.
Specifications of binary protocols, such as RFCs, also contain grammars,
although they are frequently translated into prose and diagrams as
opposed to the traditional Backus-Naur-Form.

While it is possible to express short transformations on the input
entirely as semantic actions\footnote{This is in fact the design
rationale, to perform computation on the fly as the parser walks the
parse tree.}, more complicated programs usually construct an internal
representation, which contains all relevant information from the input
in a format native to the programming language used. For example, a C
programmer ideally wants to deal with structs and NULL-terminated arrays,
whereas a C++ programmer might expect STL containers, a Java programmer
interfaces, a Haskell programmer records and a LISP programmer property
lists.  The structure of this internal representation usually resembles
the structure of the grammar.

