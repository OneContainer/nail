\section{Implementation}
\label{s:impl}

The current prototype of the Nail parser generator supports the C programming
language and top-down parsers. The implementation parses Nail grammars with Nail itself, using a 130
line Nail grammar feeding into a 2000 line C++ program that implements the parser. Bootstrapping is
performed with a subset of the grammar implemented using conventional grammars. 
Options for C++ STL data models and emitting
Packrat parsers~\cite{packrat-parsing:icfp02} are under development. In
this section, we will discuss some particular features of our parser
implementation.

% The source code of our implementation, together with the examples described in
% \S\ref{s:eval} are available on GitHub at \url{https://github.com/jbangert/nail}.


\paragraph{Parsing.}

A generated Nail parser makes two passes through the input: the first to
validate and recognize the input, and the second to bind this data to the internal
model. Currently the parser is a straightforward top-down parser, although
preparations have been made to add Packrat parsing to achieve linear parsing
times.

\paragraph{Memory allocation.}

Many security vulnerabilities can occur when heap allocations are done improperly. Therefore, just
like Hammer, Nail avoids using the heap as much as possible, using a custom arena allocator and
allocating only fixed-size blocks from the system allocator (malloc). However, Nail extends upon
Hammer's approach and uses two arenas for each parsed input. One arena is used for intermediate
structures, including dependency fields and any temporary streams, and is released (and zeroed)
after parsing completes, whereas the other arena is used only for allocating the result, and has to
be freed by the programmer.

\paragraph{Intermediate representation.}

Most parser generators, such as Bison, do not have to dynamically allocate temporary data on the
heap, as they evaluate a semantic action on every rule. However, as our goal is to perform as little
computation as possible before the input has been validated, and we do not want to mix temporary
objects with the results of our parse, we use an append-only trace to store intermediate parser
results.

Hammer solves this problem by storing a full abstract syntax tree. However, this
abstract syntax tree is at least an order of magnitude larger than the input,
because it stores a large tree node structure for each input byte and for each
rule reduced. This allows Hammer semantic actions to get all of the necessary
information without ever seeing the raw input stream. However, because we also
automatically generate our second pass, which corresponds to Hammer's semantic
actions, we can trust it as much as we trust the parser, and thus can expose it
to the raw input stream.

Under this premise, the actions need limited information from the
recognizer to correctly handle the input stream. In particular, the parser's
control flow branches only at the choice, repetition, and constant combinators.
Thus, for each of those combinators, we store the minimum amount of information
required to reconstruct the syntactic structure of the input. The trace is an
array of integers.
Whenever the parser encounters a choice, it appends two integers to the trace. After it
successfully parses a choice, the parser writes the number of that choice and
the length of the trace when it began parsing that choice. When backtracking in
the input, the parser does not backtrack in the trace. This means that offsets
within the trace can be used for a Packrat hash-table to memoize backtrack-heavy
parsers.

When encountering a repetition combinator, the parser records the number of
times the inner parser succeeded, and when encountering a constant parser of
variable size, it records how much input was consumed by the constant parser. 

In a second pass, the parser then allocates the internal representation from an
arena allocator and binds the fields to values from the input, while following
the trace to determine how many array fields to parse and which choices to pick.

% \paragraph{.}

% During parsing, dependency fields occur before the context in which they are
% used. The parser stores their values and retrieves them afterwards when
% encountering the combinator that uses them. When generating output, the
% dependency field is first filled with a filler value, then later when the first
% combinator that determines this fields value is encountered, the field is
% overwritten. Any further combinators using this dependency will then validate
% that the dependency field is correct.
