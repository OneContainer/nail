\section{Introduction}

Code that handles untrusted inputs, such as processing network
data or parsing a file, is error-prone and is often exploited by
attackers.  This is in part because attackers have precise control
over the inputs to that code, and can craft inputs that trigger
subtle corner cases in input processing.  For example, the libpng image decompression
library has had 24 remotely exploitable vulnerabilities from 2007 to
2013,\footnote{\url{http://www.cvedetails.com/vulnerability-list/vendor_id-7294/Libpng.html}}
and Adobe's PDF and Flash viewers have been notoriously
plagued by input processing vulnerabilities.  Even relatively
simple formats, such as those used by the zlib compression
library, have had input processing vulnerabilities in the
past.\footnote{\url{http://www.cvedetails.com/vulnerability-list/vendor_id-72/product_id-1820/GNU-Zlib.html}}

A promising approach to avoid such vulnerabilities is to specify
a precise grammar for the input data format, and to use a parser
generator, such as {\tt lex} and {\tt yacc}, to synthesize the input
processing code.  Developers that use a parser generator do not need
to write error-prone input processing code on their own, and as long
as the parser generator is bug-free, the application will be safe from
input processing vulnerabilities.  Unfortunately, applying this approach
in practice, using state-of-the-art parser generators, still requires
too much manual programmer effort, making it error-prone, as we describe
next.

First, parser generators typically parse inputs into an abstract syntax
tree (AST) that corresponds to the grammar.  In order to produce a data
structure that the rest of the application code can easily process,
application developers must write explicit {\em semantic actions} that
update the application's internal representation of the data based on
each AST node.  Writing these semantic actions by hand is error-prone,
much like other input processing code, and mistakes can result in memory
corruption bugs or misinterpreted inputs.  Writing these semantic actions
also requires the programmer to describe the structure of the input three
times---once to describe the grammar, once to describe the internal data
structure, and once again in the semantic actions that translate the
grammar into the data structure---leading to another potential source
of bugs and inconsistencies.

Second,  applications often need to produce output in the same
format as their input---for example, applications might both
read and write files, or both receive and send network packets.
Most parser generators focus on just parsing an input, rather
than producing an output, thus requiring the programmer to manually
construct outputs, which is error-prone.  Some parser generators, such as
Boost.Spirit~\cite{boost-spirit},
allow reusing the grammar for generating output from the internal
representation.  However, those generators require yet another set of
semantic actions to be written, transforming the internal representation
into an AST\@.

Third, many data formats contain redundancies, such as repeating information in multiple structures.
Applications usually do not explicitly check for consistency, and if different applications use
different instances of the same value, an attacker can craft input that causes inconsistencies.
Furthermore, security vulnerabilities can occur when an application assumes two repetitions of the
same data to be consistent, such as allocating a buffer based on the value of one size field and copying into
that buffer based on the value of another.

Finally, real-world data formats, for example PNG or PDF,  are hard to represent with
existing parser generators. Those parsers cannot directly deal with length or checksum fields
directly, so either the programmer has to write potentially unsafe code to deal with such features
or build contrived grammar constructs, such as introducing one grammar rule for each possible value
of a length fields. Offset fields usually require the programmer to manipulate a parser's internal
state to re-position its input. More complicated transformations on the external format, such as
compressed data, cannot be implemented at all.



This paper presents the design and implementation of Nail, a parser generator that greatly reduces
the programmer effort required to use grammars. Nail addresses the above four challenges with
several key ideas, as follows.

First, Nail grammars define both a format's external representation and an internal object model.
This removes the semantic actions and type declarations that programmers have to write with existing
parser generator. While this somewhat reduces the flexibility of the internal model, it forces the programmer
to clearly separate syntactic validation and semantic processing.

Second, this well-defined internal representation allows Nail to
maintain a {\em semantic bijection} between data formats and their
internal representation.  As a result, this enables Nail to not just
parse input but also generate output from the internal representation,
without requiring the programmer to write additional code.

% \XXX[Currently, Nail always makes a default choice when
% there are multiple options to express a constant, however Nail could be extended
% to allow a grammar-specific plug-in to make these choices, say for faster
% alignment, streaming applications when data is not ready, or visual appearance in
% human-readable protocols.]


%  However, Nail allows \emph{constants} in the
% external format to have multiple representations if they should not affect the
% semantics of the data. For example, in a text protocol, the amount of
% white-space separating tokens should not affect the meaning of the data and
% consequently Nail does not expose it to the application. As long as
% constants are only used for their intended purpose of representing syntax-only
% features, the generated output will have the same semantics as the parsed input.

Third, Nail introduces two abstractions, \emph{dependent fields} and \emph{transformations}, to
elegantly handle problematic structures, such as offset fields or checksums. Dependent fields are
fields in the protocol whose value depends in some way on the value or layout of other parts of the
format. Transformations allow the programmer to escape the generated code to modify the raw data and
interact with dependent fields in a controlled manner. 

To evaluate whether Nail's design is effective at handling real-world
data formats, we implemented a prototype of Nail for C\@.  Using our
prototype, we implemented succinct grammars for parts of an IP network
stack, for DNS packets, and for Zip files, each in about a hundred lines
of grammar.  On top of these grammars, we were able to build a fully
functional DNS server in under 200 lines of C code, and an {\tt unzip}
utility in about 50 lines of C code.  This suggests both that Nail is
effective at handling complex real-world data formats, and that Nail
makes it easy for application developers to handle external data formats.

The rest of this paper is organized as follows.  \S\ref{s:relwk}
puts Nail in the context of related work.  \S\ref{s:design} describes
Nail's design.  \S\ref{s:impl} discusses our initial implementation
of Nail.  \S\ref{s:eval} provides evaluation results.
\S\ref{s:future} suggests several directions for future work, and
\S\ref{s:concl} concludes.

