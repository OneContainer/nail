\section{Evaluation}
\label{s:eval}

\input{fig-ethernet}

In our evaluation of Nail, we try to answer four questions:

\begin{itemize}

\item Can Nail grammars support real-world data formats, and
      are Nail's techniques critical to handling these formats?

\item How much programmer effort is required to build an
      application that uses Nail for data input and output?

\item Does using Nail for handling input and output improve
      application security?

\item Does Nail achieve acceptable performance?

\end{itemize}

\subsection{Data formats}
\label{s:eval-formats}
To answer the first question, we implemented grammars for four protocols with particularly
challenging features and show that Nail is a good fit for these data formats and some aspects of
these formats would be very hard to parse with other parser generators.



In particular, we show extracts from grammars for the following protocols: 
\begin{itemize}
\item DNS messages.
\item Ethernet packets containing ARP, ICMP and UDP.
\item ZIP files.

\end{itemize}

\subsubsection{DNS.}

\input{fig-dnsfull}

\begin{figure}
\smaller[0.5]
\input{code/dns-xform}
\caption{Signatures of stream transform functions for handling DNS label compression.}
\label{fig:dns-xform}
\end{figure}

Domain Name System(DNS) packets are described in RFC 1035 and our grammar almost directly
corresponds to the diagrams in Section 4 of that document. Each DNS packet consists of a header, a
set of question records and a set of answer records. Domain names in both queries and answers are
encoded as a sequence of Pascal-style strings. Each label is preceded by a length field, and the
domain name is terminated by a $0$ octet. The client's query packet contains one question
record to the server for each DNS look-up it wants to perform. In addition to the appropriate
response records, the server's reply contains a duplicate of the client's question section, which
allows stateless DNS clients and caches.

To reduce the size overhead of including each domain name twice in a DNS reply, once in the
question section, at least once in the response record, DNS includes a label compression scheme. If
a domain name suffix is repeated, instead of repeating that suffix, the DNS packet may write a
two-bit marker sequence followed by a 14-bit offset into the packet where that suffix was previously
encoded.

Processing these encodings in existing tools, such as Bison or Hammer, would at best be very
awkward, because some ad-hoc trick would have to be used to re-position the parsers input stream.
Keeping track of the position all recognised labels would not be enough, as the offset field may
refer to any byte within the packet, not just the beginning of labels. For this reason, the DNS
server used as a tutorial example for Hammer does not support compression.

Nail handles compression with a stream transform. When parsing, this transform decompresses the DNS
label stream by following the offset pointers. When generating, this transform receives the current
suffix as an input and can scan the packet so far for previous occurrences. 


\subsubsection{Ethernet}
\XXX[TODO]
\subsubsection{ZIP Files.}
\input{fig-zip}
\label{s:eval-format-zip}
Another particularly tricky file format is the ZIP compressed archive format\cite{pkzip}.
ZIP files are normally parsed end-to-beginning. At the end of each ZIP file is an \emph{end-of-directory
header}. This header contains a variable length comment, so it has to be located by scanning
backwards from the end of the file until a magic number and a valid length field is found. Many ZIP
implementations disagree on how to find this header in confusing situations, such as when the
comment contains the valid magic bytes\cite{wolf-berlinsides-zip}.
This end-of-directory header contains the offset and size of the \emph{ZIP directory}, which is an
array of one \emph{directory entry header} per file in the archive.
Each entry stores file meta data, such as file name, compressed and uncompressed size and a checksum,
in addition to the offset of a \emph{local file header}. The local file header duplicates most
information from the directory entry header and the compressed file contents follow it immediately.

Duplicating information made sense when ZIP files were
stored on floppy disks with slow seek times and high fault rates and memory constraints made it
impossible to keep the ZIP directory in memory or the archive was split across multiple disks.
However, care must be taken that the meta-data is consistent. For example, vulnerabilities could occur
if the length in the central directory is used to allocate memory and the length in the local
directory is used to extract without checking that they are equal first. 

We have implemented a grammar for ZIP. A strongly abbreviated version is shown in
Figure~\ref{fig:zip-extract}.

Our ZIP grammar is a good example of transformations can capture complicated syntax in real-world
file format. The \cc{zip\_file} grammar first splits the entire file stream into two streams
based on the \cc{zip\_end\_of\_directory} transform.
\cc{zip\_end\_of\_directory_parse(NailStream *files, NailStream *dir, NailStream (current))}
finds the end of directory header as described above by scanning the file backwards and splits the
file into two streams, one containing the end-of-directory header and one containing the file
contents. The header stream is then parsed. The file stream, to which all the offsets in the
metadata refer, is passed as an argument to the \cc{end\_of\_directory} parser.
The directory header is then parsed and the offset and size transforms provided with Nail are used
to isolate the actual directory from the file stream. Each directory entry in turn points to a local
file header. 

The \cc{file} grammar for a zip file entry is particularly interesting. It receives the file
size, checksum and compression method of the file from the directory header. However, this same
information is duplicated in the file entry, so the grammar uses a standard \cc{depend}
transform to check whether the two values are equal. Unlike most other transforms, \cc{depend}
does not consume or produce strings, it only checks that two dependent fields are equal when parsing
and assigns the value of the second field to the first when generating. Immediately following the
file entry is the compressed data. Because most compression algorithms operate on unbounded streams
of data, Nail decompresses data in two steps.
First, it isolates the compressed data from the rest of the stream by using the size transform. In
this case, size operates on the current stream, which means it will consume data starting at the
current position of the parser in the input.
Second, Nail invokes a custom transform that implements the appropriate compression and decompression
functions based on the specified compression method. These functions are otherwise oblivious about
the layout or metadata of the file.

Existing parser languages are not able to handle a file format of this complexity.

\noindent The results suggest that Nail is a good fit for these data formats. 



\subsection{Programmer effort}


%code size unzip 6.0
%2821 lines
\label{s:eval-effort}
To answer the second question, we implemented small example applications based on the above
grammars and compared code size with comparable applications that process data manually. We will
also compare a toy DNS server implemented in Nail with a similar toy DNS server provided as an
example for the Hammer parser generator. All code size measurements for C were performed by
SlocCount\cite{sloccount}.

%%DNS: 
\paragraph{DNS.}

Our DNS grammar, which is partly reproduced in Figure~\ref{fig:dns-full}, consists of a 48 line Nail
grammar and 64 lines of C implementing DNS label compression, whose signatures are shown in
Figure~\ref{fig:dns-xform}.
The grammar describes both the structure of DNS packets (36 lines) and of a simple zone-file format
(16 lines) supporting A, NS, MX and CNAME records. 

  
With this grammar, we built a simple authoritative DNS server, which parses a zone file, listens to incoming DNS
requests, parses them and generates appropriate responses, is implemented in 183 lines of C. The
same grammar is used, together with 98 lines of C, to implement a minimal clone of the
\cc{host} command-line tool. Most of this code consists of a custom hashtable and system
interface code, such as listening to sockets and reading the zonefile. 

The Hammer parser framework\cite{hammer-dns} ships with a toy DNS server that responds to
any valid DNS query with a CNAME record to the domain ``spargelze.it''. 
The server consists of 683 lines of C, mostly custom validators, semantic actions,
and data structure definitions, with only 52 lines of code defining the
grammar with Hammer's combinators.

It is hard to compare the programming effort required to implement
our DNS server to that of a real world DNS server, since we implement less functionality.
 In particular, we do not send the additional glue records real-world DNS servers send and
we did not implement any configuration options.

However, the closest in functionality and intent is Dan Bernstein's
djbdns,\footnote{\url{http://cr.yp.to/djbdns.html}} which aims to be
a minimalist, highly secure DNS server. The latest release of djbdns,
including various support tools, is about 10,000 lines of C as measured by
\cc{sloccount}. \XXX[Show that we only count the DNS server parts, not the rest. List some
features we don't have]

\paragraph{ZIP.}


We wrote a grammar for ZIP, which consists of 92 lines of Nail and 78 lines of C implementing two
stream transforms, one for the DEFLATE compression algorithm with the help of the zlib library and
one for finding the end-of-directory header. 

Our grammar is also very efficient to use. Using our grammar, we build a ZIP file extractor in 50
lines of C. Because more recent versions of ZIP have added more features, such as large file support
and encryption, the closest existing tool in functionality is the historic version 5.4 of the Info-Zip unzip
utility\cite{infozip} that is shipped with most Linux distributions. The entire unzip distribution
is about 46.000 lines of code, which is mostly optimised implementation of various compression
algorithms and other configuration and portability code.

However, unzip isolates the equivalent of our Nail tool in the file extract.c, which parses the ZIP
metadata and calls various decompression routines in other files. This file measures over 1,600
lines of C. 

\paragraph{Network stack.}
\XXX[Write this up]
\subsection{Security.} 
We use a twofold approach to evaluate the security of applications implemented with Nail. First, we
analyse a list of CVE's related to the ZIP file format and argue how our ZIP tools based on Nail are
immune against those vulnerability classes. Second, we present the results of fuzz-testing our DNS
server.

The ZIP format has been associated with many vulnerabilities, and the PROTOS Genome project found numerous
security vulnerabilities in most implementations of ZIP and other archive formats that are directly
related to input handling.

Between May 2011 and May 2014, the CVE database\cite{cve-database} lists 83 vulnerabilities when searching for the
string ``ZIP''. Of these, 42 were completely unrelated to the archive format, for example reporting
vulnerabilities revealing Zip codes of other users. 26 vulnerabilities were related to ZIP archives,
but not to input processing, such as trusting arbitrary update ZIP files sent to a server or
vulnerabilities that can be accessed through manipulating files in a ZIP container. This includes
several vulnerabilities allowing another files to replaced while they are extracted from ZIP
files because insufficiently secure temporary directories are used. Of the 15 remaining
vulnerabilities pertaining to ZIP files, 14 vulnerabilities were related to input processing. The
 other vulnerability, which falls outside of Nails purview, concerns a ZIP packer choosing a weak
 legacy cryptosystem even when configured to use AES.

 Nail parsers are immune by design to vulnerabilities like these 14. Ten of those vulnerabilities
 are memory corruption attacks, that could also be avoided by using safer languages or better
 verification tools. Most of the buffer overflows seem to result from inconsistent offset fields
 being manipulated without checking. Because Nail's generated code checks offsets before reading and
 does not expose any untrusted pointers to the application, it protects against memory corruption
 attacks by design.

The remaining four vulnerabilities do not involve memory corruption, but rather parser ambiguities.
Two of them relate to implementations mis-parsing ZIP files, particularly in virus scanners. One
other vulnerability is in a Python ZIP library, which uses both the size field in the file entry and
in the header, without checking for their consistency. This results in a denial-of-service through
endless loops or incorrectly extracted ZIP files.

A similar attack was used by the fourth vulnerability, the infamous Android master key bug
\cite{saurik-masterkey}, that completely by-passed Android security multiple times through parser
differentials between the ZIP handler that checks signatures for privileged applications and the ZIP
implementations that ultimately extracts those files. Thus, valid  application bundles could be
modified to include malicious applications without breaking their signatures. Instead of both
components containing an ad-hoc archive implementation, a single Nail grammar would be reusable
across both implementations. 
\subsection{Performance.}
\input{fig-perf-dns}
To estimate the performance impact of using Nail grammars as opposed to hand-written grammars, we
benchmarked our DNS server against BIND.

We compare the performance of our DNS server to the release 9.9.5 of ISC BIND 9\cite{bind8}, one of
the oldest and most popular DNS daemons, on a load that resembles the authoritative name server at a
hosting company. First, we generated domain names consisting of one or
two labels randomly selected from an English dictionary and one label that is one of three popular
Top Level Domains: ``com'', ``net'' or ``org''. Second, we randomly selected 90\% of these domains and
created a zone file that mapped these domain names to the local IP address. 

Finally, we used the \cc{queryperf} tool provided with BIND to query each domain between zero
and three times on a local instance of BIND or NailDNS. Both DNS servers were operating on a single, 
core  of an Intel i7-3610QM with 12GB of RAM on an idle system, and the benchmark tool kept at most 20
queries outstanding at once. The queryperf tool was configured to
repeat the same, randomised sequence of queries for one minute and the average throughput and
response latency were measured.  We repeated each test seven times  with 50.000
domain names, restarting each daemon in between. We also performed one initial dry run to warm the
file system cache for the zone file. We repeated the tests with 1 million domain names and found
that the servers performed almost identically.

Surprisingly, our simple Nail server outperforms the established BIND server that has seen decades
of optimisation by a factor of 3.  This demonstrates that even though Nail was
not developed focusing on performance, applications built on Nail can compete with real-world
hand-written parsers.



